{
  "event_type": "load",
  "uuid": "f02c29dd-729e-48ef-b158-642f5e3941b8",
  "timestamp": "2025-08-25T06:42:28.945262+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "Loaded table from ../test_tables/test2.csv as csv (pyspark)",
  "description": "Loaded  from ../test_tables/test2.csv"
}
{
  "event_type": "transform",
  "uuid": "edd5e11b-dee7-4e87-b13d-5087e4e72fb3",
  "timestamp": "2025-08-25T06:42:31.594496+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "SubsetTable",
  "description": "Subsets a dataframe to retain only specified variable(s)",
  "name": "SubsetTable",
  "transform_type": "TableTransform",
  "testable_transform": true,
  "version_pyspark": "4.0.0",
  "version_polars": "1.31.0",
  "version_pandas": "2.3.0",
  "version_python": "3.10.8",
  "transform_id": "SubsetTbl",
  "target_tables": [
    "test_table2"
  ],
  "target_variables": [
    "SALARY",
    "AGE"
  ],
  "created_variables": null,
  "renamed_variables": null,
  "deleted_variables": [
    "NAME"
  ],
  "hashed_variables": null
}
{
  "event_type": "transform",
  "uuid": "e72d520a-cb1b-4fcb-8bf6-72d46d62c969",
  "timestamp": "2025-08-25T06:42:32.458497+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "DistinctTable",
  "description": "Removes duplicate rows from a DataFrame",
  "name": "DistinctTable",
  "transform_type": "TableTransform",
  "testable_transform": false,
  "version_pyspark": "4.0.0",
  "version_polars": "1.31.0",
  "version_pandas": "2.3.0",
  "version_python": "3.10.8",
  "transform_id": "DistinctTbl",
  "target_tables": [
    "test_table2"
  ],
  "target_variables": [],
  "created_variables": null,
  "renamed_variables": null,
  "deleted_variables": null,
  "hashed_variables": null
}
{
  "event_type": "transform",
  "uuid": "cceea93d-bb13-4e1d-8632-8769b7bd7e93",
  "timestamp": "2025-08-25T06:42:32.967012+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "RenameTable",
  "description": "Renames specified columns in a dataframe",
  "name": "RenameTable",
  "transform_type": "TableTransform",
  "testable_transform": true,
  "version_pyspark": "4.0.0",
  "version_polars": "1.31.0",
  "version_pandas": "2.3.0",
  "version_python": "3.10.8",
  "transform_id": "RenmTbl",
  "target_tables": [
    "test_table2"
  ],
  "target_variables": [
    "SALARY"
  ],
  "created_variables": null,
  "renamed_variables": null,
  "deleted_variables": null,
  "hashed_variables": null,
  "rename_map": {
    "SALARY": "INCOME"
  },
  "new_names": [
    "INCOME"
  ]
}
{
  "event_type": "transform",
  "uuid": "6a411a5a-e83f-4f3b-bfc4-7ab844b142a4",
  "timestamp": "2025-08-25T06:42:33.208012+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "FilterTransform",
  "description": "Filters rows in a dataframe using a backend-specific condition",
  "name": "FilterTransform",
  "transform_type": "TableTransform",
  "testable_transform": false,
  "version_pyspark": "4.0.0",
  "version_polars": "1.31.0",
  "version_pandas": "2.3.0",
  "version_python": "3.10.8",
  "transform_id": "RowFilter",
  "target_tables": [
    "test_table2"
  ],
  "target_variables": [],
  "created_variables": null,
  "renamed_variables": null,
  "deleted_variables": null,
  "hashed_variables": null,
  "backend": "pyspark",
  "condition_string": "\"pyspark\": lambda df: df.filter(col(\"INCOME\") >= 600)"
}
