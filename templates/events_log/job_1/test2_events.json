{
  "event_type": "load",
  "uuid": "d2623f7c-d5c6-4421-8737-f91a3ec360c1",
  "timestamp": "2025-08-25T05:14:50.302447+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "Loaded table from ../test_tables/test2.csv as csv (pyspark)",
  "description": "Loaded  from ../test_tables/test2.csv"
}
{
  "event_type": "transform",
  "uuid": "409777f3-0e75-470b-bcdd-c83a733ad010",
  "timestamp": "2025-08-25T05:14:50.615478+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "SubsetTable",
  "description": "Subsets a dataframe to retain only specified variable(s)",
  "name": "SubsetTable",
  "transform_type": "TableTransform",
  "testable_transform": true,
  "version_pyspark": "4.0.0",
  "version_polars": "1.31.0",
  "version_pandas": "2.3.0",
  "version_python": "3.10.8",
  "transform_id": "SubsetTbl",
  "target_tables": [
    "test_table2"
  ],
  "target_variables": [
    "SALARY",
    "AGE"
  ],
  "created_variables": null,
  "renamed_variables": null,
  "deleted_variables": [
    "NAME"
  ],
  "hashed_variables": null
}
{
  "event_type": "transform",
  "uuid": "c9ec90dc-827e-4c3b-973b-cb288b8b62eb",
  "timestamp": "2025-08-25T05:14:52.113601+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "DistinctTable",
  "description": "Removes duplicate rows from a DataFrame",
  "name": "DistinctTable",
  "transform_type": "TableTransform",
  "testable_transform": false,
  "version_pyspark": "4.0.0",
  "version_polars": "1.31.0",
  "version_pandas": "2.3.0",
  "version_python": "3.10.8",
  "transform_id": "DistinctTbl",
  "target_tables": [
    "test_table2"
  ],
  "target_variables": [],
  "created_variables": null,
  "renamed_variables": null,
  "deleted_variables": null,
  "hashed_variables": null
}
{
  "event_type": "transform",
  "uuid": "e23e035a-55a5-4c31-9faa-da68f7577fd8",
  "timestamp": "2025-08-25T05:14:52.561117+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "RenameTable",
  "description": "Renames specified columns in a dataframe",
  "name": "RenameTable",
  "transform_type": "TableTransform",
  "testable_transform": true,
  "version_pyspark": "4.0.0",
  "version_polars": "1.31.0",
  "version_pandas": "2.3.0",
  "version_python": "3.10.8",
  "transform_id": "RenmTbl",
  "target_tables": [
    "test_table2"
  ],
  "target_variables": [
    "SALARY"
  ],
  "created_variables": null,
  "renamed_variables": null,
  "deleted_variables": null,
  "hashed_variables": null,
  "rename_map": {
    "SALARY": "INCOME"
  },
  "new_names": [
    "INCOME"
  ]
}
{
  "event_type": "transform",
  "uuid": "4ecb8f8f-e48d-4228-8919-0e219f842a7f",
  "timestamp": "2025-08-25T05:14:52.788115+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "FilterTransform",
  "description": "Filters rows in a dataframe using a backend-specific condition",
  "name": "FilterTransform",
  "transform_type": "TableTransform",
  "testable_transform": false,
  "version_pyspark": "4.0.0",
  "version_polars": "1.31.0",
  "version_pandas": "2.3.0",
  "version_python": "3.10.8",
  "transform_id": "RowFilter",
  "target_tables": [
    "test_table2"
  ],
  "target_variables": [],
  "created_variables": null,
  "renamed_variables": null,
  "deleted_variables": null,
  "hashed_variables": null,
  "backend": "pyspark",
  "condition_string": "\"pyspark\": lambda df: df.filter(col(\"INCOME\") >= 600)"
}
