{
  "event_type": "load",
  "uuid": "e387a6b4-1a68-448c-a4a8-b25f1cf12986",
  "timestamp": "2025-08-28T10:22:15.489176+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "Loaded table from ../test_tables/salary.csv as csv (pyspark)",
  "description": "Loaded  from ../test_tables/salary.csv",
  "filepath": "../test_tables/salary.csv",
  "table_name": "",
  "src_format": "csv"
}
{
  "event_type": "transform",
  "uuid": "666047be-f794-43d1-a94b-9a32ac22e2b9",
  "timestamp": "2025-08-28T10:22:17.983284+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "SubsetTable",
  "description": "Subsets a dataframe to retain only specified variable(s)",
  "name": "SubsetTable",
  "transform_type": "TableTransform",
  "testable_transform": true,
  "version_pyspark": "4.0.0",
  "version_polars": "1.32.3",
  "version_pandas": "2.3.2",
  "version_python": "3.10.8",
  "transform_id": "SubsetTbl",
  "target_tables": [
    "salary"
  ],
  "target_variables": [
    "SALARY",
    "AGE"
  ],
  "created_variables": null,
  "renamed_variables": null,
  "deleted_variables": [
    "NAME"
  ],
  "hashed_variables": null
}
{
  "event_type": "transform",
  "uuid": "409c0bdc-17d5-4e4b-9220-53b54d5303ea",
  "timestamp": "2025-08-28T10:22:18.604801+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "DistinctTable",
  "description": "Removes duplicate rows from a DataFrame",
  "name": "DistinctTable",
  "transform_type": "TableTransform",
  "testable_transform": false,
  "version_pyspark": "4.0.0",
  "version_polars": "1.32.3",
  "version_pandas": "2.3.2",
  "version_python": "3.10.8",
  "transform_id": "DistinctTbl",
  "target_tables": [
    "salary"
  ],
  "target_variables": [],
  "created_variables": null,
  "renamed_variables": null,
  "deleted_variables": null,
  "hashed_variables": null
}
{
  "event_type": "transform",
  "uuid": "25d14e95-4a59-4e4d-a4f7-772d08c76d81",
  "timestamp": "2025-08-28T10:22:19.001800+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "RenameTable",
  "description": "Renames specified columns in a dataframe",
  "name": "RenameTable",
  "transform_type": "TableTransform",
  "testable_transform": true,
  "version_pyspark": "4.0.0",
  "version_polars": "1.32.3",
  "version_pandas": "2.3.2",
  "version_python": "3.10.8",
  "transform_id": "RenmTbl",
  "target_tables": [
    "salary"
  ],
  "target_variables": [
    "SALARY"
  ],
  "created_variables": null,
  "renamed_variables": null,
  "deleted_variables": null,
  "hashed_variables": null,
  "rename_map": {
    "SALARY": "INCOME"
  },
  "new_names": [
    "INCOME"
  ]
}
{
  "event_type": "transform",
  "uuid": "ecb127f8-370d-405b-896a-81f49f80d30c",
  "timestamp": "2025-08-28T10:22:19.233841+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "ComplexFilter",
  "description": "Filters rows in a dataframe using a backend-specific condition",
  "name": "ComplexFilter",
  "transform_type": "TableTransform",
  "testable_transform": false,
  "version_pyspark": "4.0.0",
  "version_polars": "1.32.3",
  "version_pandas": "2.3.2",
  "version_python": "3.10.8",
  "transform_id": "RowFilter",
  "target_tables": [
    "salary"
  ],
  "target_variables": [],
  "created_variables": null,
  "renamed_variables": null,
  "deleted_variables": null,
  "hashed_variables": null,
  "backend": "pyspark",
  "condition_string": "\"pyspark\": lambda df: df.filter(col(\"INCOME\") >= 600)"
}
{
  "event_type": "write",
  "uuid": "4da20657-19a9-4573-9750-db8800ec5eb3",
  "timestamp": "2025-08-28T10:22:23.191539+00:00",
  "excuted_user": "Daniel",
  "sub_type": "pipeline_event",
  "message": "Wrote table to ../test_tables/output/salary.parquet as parquet (pyspark)",
  "description": "Wrote salary to ../test_tables/output/salary.parquet with mode=True",
  "filepath": "../test_tables/output/salary.parquet",
  "table_name": "salary",
  "src_format": "parquet"
}
