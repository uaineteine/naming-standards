{
  "log_info": {
    "filepath": "../test_tables/job_1/salary.csv",
    "table_name": "",
    "src_format": "csv"
  },
  "uuid": "f065c090-c90b-4146-b55e-cb773cd0e12d",
  "timestamp": "2025-09-11T15:14:41.324002+00:00",
  "executed_user": "Daniel Stamer-Squair",
  "macro_uuid": null,
  "event_type": "load",
  "event_description": "Loaded  from ../test_tables/job_1/salary.csv",
  "meta_version": "1.0",
  "class_type": "PipelineEvent"
}
{
  "log_info": {
    "input_tables": [
      "salary"
    ],
    "output_tables": [
      "salary_700",
      "salary_620",
      "salary_500",
      "salary_600",
      "salary_400"
    ],
    "input_variables": [
      [
        "SALARY"
      ]
    ],
    "output_variables": [],
    "created_variables": null,
    "renamed_variables": null,
    "removed_variables": null,
    "num_input_frames": 1,
    "num_output_frames": 5
  },
  "uuid": "e9792337-d77d-4bc7-9cdd-d3c53096e11d",
  "timestamp": "2025-09-11T15:14:42.119608+00:00",
  "executed_user": "Daniel Stamer-Squair",
  "macro_uuid": null,
  "event_type": "transform",
  "event_description": "Partitions a DataFrame into subtables by 'SALARY'",
  "meta_version": "1.0",
  "name": "PartitionByValue",
  "transform_type": "TableTransform",
  "testable_transform": true,
  "version_pyspark": "4.0.0",
  "version_polars": "1.33.0",
  "version_pandas": "2.3.2",
  "version_python": "3.11.9",
  "params": {
    "df": "salary"
  },
  "transform_id": "PartVal",
  "target_tables": [
    "salary_700",
    "salary_620",
    "salary_500",
    "salary_600",
    "salary_400"
  ],
  "target_variables": [
    "SALARY"
  ],
  "partition_column": "SALARY",
  "suffix_format": "_{value}",
  "class_type": "PartitionByValue"
}
{
  "log_info": {
    "filepath": "..\\test_tables\\output\\salary_600.parquet",
    "table_name": {},
    "out_format": "parquet"
  },
  "uuid": "f8fa11cb-e52c-4b05-8bf7-d17e1743a1a6",
  "timestamp": "2025-09-11T15:14:53.512304+00:00",
  "executed_user": "Daniel Stamer-Squair",
  "macro_uuid": null,
  "event_type": "write",
  "event_description": "Wrote table to ..\\test_tables\\output\\salary_600.parquet as parquet (pyspark)",
  "meta_version": "1.0",
  "filepath": "..\\test_tables\\output\\salary_600.parquet",
  "table_name": {},
  "src_format": "parquet",
  "class_type": "PipelineEvent"
}
