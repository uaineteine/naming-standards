{
  "log_info": {
    "filepath": "../test_tables/job_1/salary.csv",
    "table_name": "",
    "src_format": "csv"
  },
  "uuid": "b64cb7bf-def0-45f4-bd44-4f769876b192",
  "timestamp": "2025-09-11T15:14:41.324002+00:00",
  "executed_user": "Daniel Stamer-Squair",
  "macro_uuid": null,
  "event_type": "load",
  "event_description": "Loaded  from ../test_tables/job_1/salary.csv",
  "meta_version": "1.0",
  "class_type": "PipelineEvent"
}
{
  "log_info": {
    "input_tables": [
      "salary"
    ],
    "output_tables": [
      "salary"
    ],
    "input_variables": [
      [
        "SALARY",
        "AGE"
      ]
    ],
    "output_variables": [],
    "created_variables": null,
    "renamed_variables": null,
    "removed_variables": [
      "NAME"
    ],
    "num_input_frames": 1,
    "num_output_frames": 1
  },
  "uuid": "fd94d60c-409b-4716-b0ae-7f1c0c6c8af1",
  "timestamp": "2025-09-11T15:14:44.906889+00:00",
  "executed_user": "Daniel Stamer-Squair",
  "macro_uuid": null,
  "event_type": "transform",
  "event_description": "Subsets a dataframe to retain only specified variable(s)",
  "meta_version": "1.0",
  "name": "SubsetTable",
  "transform_type": "TableTransform",
  "testable_transform": true,
  "version_pyspark": "4.0.0",
  "version_polars": "1.33.0",
  "version_pandas": "2.3.2",
  "version_python": "3.11.9",
  "params": {
    "df": "salary"
  },
  "transform_id": "SubsetTbl",
  "target_tables": [
    "salary"
  ],
  "target_variables": [
    "SALARY",
    "AGE"
  ],
  "class_type": "SubsetTable"
}
{
  "log_info": {
    "input_tables": [
      "salary"
    ],
    "output_tables": [
      "salary"
    ],
    "input_variables": [],
    "output_variables": [],
    "created_variables": null,
    "renamed_variables": null,
    "removed_variables": null,
    "num_input_frames": 1,
    "num_output_frames": 1
  },
  "uuid": "190c3aad-8ba3-464b-8cf5-0f611a820fe4",
  "timestamp": "2025-09-11T15:14:45.590877+00:00",
  "executed_user": "Daniel Stamer-Squair",
  "macro_uuid": null,
  "event_type": "transform",
  "event_description": "Removes duplicate rows from a DataFrame",
  "meta_version": "1.0",
  "name": "DistinctTable",
  "transform_type": "TableTransform",
  "testable_transform": false,
  "version_pyspark": "4.0.0",
  "version_polars": "1.33.0",
  "version_pandas": "2.3.2",
  "version_python": "3.11.9",
  "params": {
    "df": "salary"
  },
  "transform_id": "DistinctTbl",
  "target_tables": [
    "salary"
  ],
  "target_variables": [],
  "class_type": "DistinctTable"
}
{
  "log_info": {
    "input_tables": [
      "salary"
    ],
    "output_tables": [
      "salary"
    ],
    "input_variables": [
      [
        "SALARY"
      ]
    ],
    "output_variables": [
      [
        "INCOME"
      ]
    ],
    "created_variables": null,
    "renamed_variables": null,
    "removed_variables": null,
    "num_input_frames": 1,
    "num_output_frames": 1
  },
  "uuid": "e2b3caab-2802-426f-b391-b973e9377aba",
  "timestamp": "2025-09-11T15:14:45.968548+00:00",
  "executed_user": "Daniel Stamer-Squair",
  "macro_uuid": null,
  "event_type": "transform",
  "event_description": "Renames specified columns in a dataframe",
  "meta_version": "1.0",
  "name": "RenameTable",
  "transform_type": "TableTransform",
  "testable_transform": true,
  "version_pyspark": "4.0.0",
  "version_polars": "1.33.0",
  "version_pandas": "2.3.2",
  "version_python": "3.11.9",
  "params": {
    "df": "salary"
  },
  "transform_id": "RenmTbl",
  "target_tables": [
    "salary"
  ],
  "target_variables": [
    "SALARY"
  ],
  "rename_map": {
    "SALARY": "INCOME"
  },
  "new_names": [
    "INCOME"
  ],
  "class_type": "RenameTable"
}
{
  "log_info": {
    "input_tables": [
      "salary"
    ],
    "output_tables": [
      "salary"
    ],
    "input_variables": [],
    "output_variables": [],
    "created_variables": null,
    "renamed_variables": null,
    "removed_variables": null,
    "num_input_frames": 1,
    "num_output_frames": 1
  },
  "uuid": "8ab4d28e-fb65-4fe6-8096-93f591a237b9",
  "timestamp": "2025-09-11T15:14:46.074832+00:00",
  "executed_user": "Daniel Stamer-Squair",
  "macro_uuid": null,
  "event_type": "transform",
  "event_description": "Filters rows in a dataframe using a backend-specific condition",
  "meta_version": "1.0",
  "name": "ComplexFilter",
  "transform_type": "TableTransform",
  "testable_transform": false,
  "version_pyspark": "4.0.0",
  "version_polars": "1.33.0",
  "version_pandas": "2.3.2",
  "version_python": "3.11.9",
  "params": {
    "df": "salary"
  },
  "transform_id": "RowFilter",
  "target_tables": [
    "salary"
  ],
  "target_variables": [],
  "condition_map": {
    "pyspark": {}
  },
  "backend": "pyspark",
  "condition_string": "\"pyspark\": lambda df: df.filter(col(\"INCOME\") >= 600)",
  "class_type": "ComplexFilter"
}
{
  "log_info": {
    "filepath": "..\\test_tables\\output\\salary.parquet",
    "table_name": {},
    "out_format": "parquet"
  },
  "uuid": "250485cb-b7ed-4988-86dc-84ddb6c31028",
  "timestamp": "2025-09-11T15:14:53.907377+00:00",
  "executed_user": "Daniel Stamer-Squair",
  "macro_uuid": null,
  "event_type": "write",
  "event_description": "Wrote table to ..\\test_tables\\output\\salary.parquet as parquet (pyspark)",
  "meta_version": "1.0",
  "filepath": "..\\test_tables\\output\\salary.parquet",
  "table_name": {},
  "src_format": "parquet",
  "class_type": "PipelineEvent"
}
